{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### BERT-Danish\n",
    "\n",
    "Download the model and vocab from https://github.com/botxo/nordic_bert. Place them in folder named models.\n",
    "\n",
    "```bash\n",
    "conda create -n bert -c conda-forge python=3.7 watermark jupyterlab ipykernel ipywidgets gensim scikit-learn pandas seaborn tqdm\n",
    "conda activate bert\n",
    "conda install tensorflow-estimator=2.1\n",
    "conda install tensorflow-gpu=2.1\n",
    "pip install bert-for-tf2 sentencepiece transformers\n",
    "python -m ipykernel install --user --name bert --display-name \"Bert\"\n",
    "conda install -c anaconda tensorflow-datasets\n",
    "jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prayson W. Daniel \n",
      "last updated: Sat Sep 12 2020 Romance Daylight Time 2020-09-12T08:09:50+02:00\n",
      "\n",
      "CPython 3.7.8\n",
      "IPython 7.17.0\n",
      "\n",
      "pandas 1.1.2\n",
      "numpy 1.19.1\n",
      "matplotlib 3.3.1\n",
      "tensorflow 2.1.0\n",
      "bert 0.14.6\n",
      "gensim not installed\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 158 Stepping 13, GenuineIntel\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n",
      "Sat Sep 12 08:10:20 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 442.83       Driver Version: 442.83       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 3000    WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   38C    P8    16W /  N/A |    164MiB /  6144MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Works only on jupyter lab/notebooks\n",
    "%reload_ext watermark\n",
    "%watermark -uniz --author \"Prayson W. Daniel\" -vm -p pandas,numpy,matplotlib,tensorflow,bert,gensim\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert:\n",
    "    def __init__(self, input_shape, model_dir, vocab_file):\n",
    "        '''\n",
    "        input = MAX_SEQ_LENGTH\n",
    "        model_dir = MODEL_DIRECTORY\n",
    "        vocal_file = VOCAB_FILE\n",
    "        '''\n",
    "        \n",
    "        # Input Layer\n",
    "        input_layer =  tf.keras.layers.Input(shape=(input_shape,),\n",
    "                                        dtype='int32')\n",
    "        \n",
    "        # Bert Layer\n",
    "        bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "        bert_layer = bert.BertModelLayer.from_params(bert_params, name='bert')\n",
    "        \n",
    "        # Output Layer\n",
    "        output_layer = bert_layer(input_layer)\n",
    "        \n",
    "        \n",
    "        # Build Model\n",
    "        model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.build(input_shape=(None, input_shape))\n",
    "        \n",
    "        \n",
    "        # To use in functions\n",
    "        self.input_shape = input_shape\n",
    "        self.model = model\n",
    "        self.tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file)\n",
    "        \n",
    "    def generate_embeddings(self, text):\n",
    "        text_ids =  self._convert_text_to_ids(text)\n",
    "        return self.model.predict([text_ids])\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Utils    \n",
    "    def _convert_text_ids(self, tokens):\n",
    "        \n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "        return tokens_ids + [0]*(self.input_shape - len(tokens_ids))\n",
    "    \n",
    "    def _convert_text_to_tokens(self, text):\n",
    "        \n",
    "        return ['[CLS]'] + self.tokenizer.tokenize(text) + ['[SEP]']\n",
    "    \n",
    "    def _convert_text_to_ids(self, text):\n",
    "        \n",
    "        tokens =self._convert_text_to_tokens(text)\n",
    "        \n",
    "        return self._convert_text_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'models/danish_bert_uncased_v2/'\n",
    "VOCAB_FILE = f'{MODEL_DIR}/vocab.txt'\n",
    "MAX_SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Bert(input_shape=MAX_SEQ_LENGTH, model_dir=MODEL_DIR, vocab_file=VOCAB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 128, 768)          110025216 \n",
      "=================================================================\n",
      "Total params: 110,025,216\n",
      "Trainable params: 110,025,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(b.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "text = 'Hej min skat pige!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.566651    0.76866275  0.7201991  ...  0.49181592 -0.71183765\n",
      "   -0.56769574]\n",
      "  [ 2.2829924  -0.078491    1.0017303  ...  0.9041473  -1.0147523\n",
      "    0.15431353]\n",
      "  [-0.9577784   0.36371198 -0.25006995 ... -1.3931506  -0.01940357\n",
      "    1.3867458 ]\n",
      "  ...\n",
      "  [ 0.5891271  -0.6892314  -0.46708322 ... -0.95656055 -1.0666904\n",
      "    1.4403996 ]\n",
      "  [ 1.3486811  -1.0827739   0.615178   ...  0.0667549  -1.5458696\n",
      "    1.3150258 ]\n",
      "  [ 1.1293281  -0.79656374  0.11924702 ...  0.3409599  -1.3880537\n",
      "    1.7114571 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(b.generate_embeddings(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
